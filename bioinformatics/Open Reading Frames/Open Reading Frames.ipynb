{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGCCATGTAGCTAACTCAGGTTACATGGGGATGACCCCGCGACTTGGATTAGAGTCTCTTTTGGAATAAGCCTGAATGATCCGAGTAGCATCTCAG\n"
     ]
    }
   ],
   "source": [
    "# reading in fasta sequence\n",
    "with open('input.txt', 'r') as raw_fasta:\n",
    "    seq = ''.join(raw_fasta.read().splitlines()[1:])\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAGATGCTACTCGGATCATTCAGGCTTATTCCAAAAGAGACTCTAATCCAAGTCGCGGGGTCATCCCCATGTAACCTGAGTTAGCTACATGGCT\n"
     ]
    }
   ],
   "source": [
    "# get reverse complement for later\n",
    "complement_dict = {'A':'T', 'T':'A', 'C':'G', 'G':'C'}\n",
    "reverse_complement = ''.join([complement_dict[nuc] for nuc in seq][::-1])\n",
    "print(reverse_complement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGCCATGTAGCTAACTCAGGTTACATGGGGATGACCCCGCGACTTGGATTAGAGTCTCTTTTGGAATAAGCCTGAATGATCCGAGTAGCATCTCAG', 'GCCATGTAGCTAACTCAGGTTACATGGGGATGACCCCGCGACTTGGATTAGAGTCTCTTTTGGAATAAGCCTGAATGATCCGAGTAGCATCTCAG', 'CCATGTAGCTAACTCAGGTTACATGGGGATGACCCCGCGACTTGGATTAGAGTCTCTTTTGGAATAAGCCTGAATGATCCGAGTAGCATCTCAG', 'CTGAGATGCTACTCGGATCATTCAGGCTTATTCCAAAAGAGACTCTAATCCAAGTCGCGGGGTCATCCCCATGTAACCTGAGTTAGCTACATGGCT', 'TGAGATGCTACTCGGATCATTCAGGCTTATTCCAAAAGAGACTCTAATCCAAGTCGCGGGGTCATCCCCATGTAACCTGAGTTAGCTACATGGCT', 'GAGATGCTACTCGGATCATTCAGGCTTATTCCAAAAGAGACTCTAATCCAAGTCGCGGGGTCATCCCCATGTAACCTGAGTTAGCTACATGGCT']\n"
     ]
    }
   ],
   "source": [
    "# generate all 6 reading frames(3 from original string, 3 from reverse complement)\n",
    "\n",
    "rf_original = [seq[i:] for i in range(3)]\n",
    "rf_reverse_complement = [reverse_complement[i:] for i in range(3)]\n",
    "rf = rf_original + rf_reverse_complement\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['AGC', 'CAT', 'GTA', 'GCT', 'AAC', 'TCA', 'GGT', 'TAC', 'ATG', 'GGG', 'ATG', 'ACC', 'CCG', 'CGA', 'CTT', 'GGA', 'TTA', 'GAG', 'TCT', 'CTT', 'TTG', 'GAA', 'TAA', 'GCC', 'TGA', 'ATG', 'ATC', 'CGA', 'GTA', 'GCA', 'TCT', 'CAG'], 2: ['GCC', 'ATG', 'TAG', 'CTA', 'ACT', 'CAG', 'GTT', 'ACA', 'TGG', 'GGA', 'TGA', 'CCC', 'CGC', 'GAC', 'TTG', 'GAT', 'TAG', 'AGT', 'CTC', 'TTT', 'TGG', 'AAT', 'AAG', 'CCT', 'GAA', 'TGA', 'TCC', 'GAG', 'TAG', 'CAT', 'CTC'], 3: ['CCA', 'TGT', 'AGC', 'TAA', 'CTC', 'AGG', 'TTA', 'CAT', 'GGG', 'GAT', 'GAC', 'CCC', 'GCG', 'ACT', 'TGG', 'ATT', 'AGA', 'GTC', 'TCT', 'TTT', 'GGA', 'ATA', 'AGC', 'CTG', 'AAT', 'GAT', 'CCG', 'AGT', 'AGC', 'ATC', 'TCA'], 4: ['CTG', 'AGA', 'TGC', 'TAC', 'TCG', 'GAT', 'CAT', 'TCA', 'GGC', 'TTA', 'TTC', 'CAA', 'AAG', 'AGA', 'CTC', 'TAA', 'TCC', 'AAG', 'TCG', 'CGG', 'GGT', 'CAT', 'CCC', 'CAT', 'GTA', 'ACC', 'TGA', 'GTT', 'AGC', 'TAC', 'ATG', 'GCT'], 5: ['TGA', 'GAT', 'GCT', 'ACT', 'CGG', 'ATC', 'ATT', 'CAG', 'GCT', 'TAT', 'TCC', 'AAA', 'AGA', 'GAC', 'TCT', 'AAT', 'CCA', 'AGT', 'CGC', 'GGG', 'GTC', 'ATC', 'CCC', 'ATG', 'TAA', 'CCT', 'GAG', 'TTA', 'GCT', 'ACA', 'TGG'], 6: ['GAG', 'ATG', 'CTA', 'CTC', 'GGA', 'TCA', 'TTC', 'AGG', 'CTT', 'ATT', 'CCA', 'AAA', 'GAG', 'ACT', 'CTA', 'ATC', 'CAA', 'GTC', 'GCG', 'GGG', 'TCA', 'TCC', 'CCA', 'TGT', 'AAC', 'CTG', 'AGT', 'TAG', 'CTA', 'CAT', 'GGC']}\n"
     ]
    }
   ],
   "source": [
    "# find ORF of one reading frame.\n",
    "import re\n",
    "rf_codons = {}\n",
    "for ind, rf_indiv in enumerate(rf):\n",
    "    rf_codons[ind + 1] = [rf_indiv[i:i + 3] for i in range(0,(len(rf_indiv) // 3) * 3, 3)]\n",
    "print(rf_codons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing making a json\n",
    "import json\n",
    "\n",
    "with open('json_test', 'w') as write_file:\n",
    "    json.dump(rf_codons, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [array([ 8, 10, 25]), array([22, 24])], 2: [array([1]), array([ 2, 10, 16, 25, 28])], 3: [array([], dtype=float64), array([3])], 4: [array([30]), array([15, 26])], 5: [array([23]), array([ 0, 24])], 6: [array([1]), array([27])]}\n"
     ]
    }
   ],
   "source": [
    "# find all indices of 'ATG' start codon\n",
    "import numpy as np\n",
    "start_stop_dict = {}\n",
    "for ind, codons in rf_codons.items():\n",
    "    start_stop_dict[ind] = [np.array([index for index, codon in enumerate(codons) if codon == 'ATG']), np.array([index for index, codon in enumerate(codons) if codon in ('TGA', 'TAA', 'TAG')])]\n",
    "\n",
    "print(start_stop_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 conditions\n",
    "1. start or stop codons codons empty -> no operations needed\n",
    "2. at least 1 element in stop and start codon indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -1,  0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3]) - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([14, 16]), array([12, 14]), array([-3, -1])]\n"
     ]
    }
   ],
   "source": [
    "# correct algorithm for finding all indexes of all ORF's for one total reading frame\n",
    "# output is a list of lists ex [8,22], []\n",
    "test = start_stop_dict[1]\n",
    "# print(test[0])\n",
    "if (test[0].size > 0) and (test[1].size > 0): # check there are no empty inds in either start or stop inds.\n",
    "    # each start codon may or may not have an ORF, the maximum # of ORF's per frame = # of start codons in frame.\n",
    "    # if this calculation contains a + value, then there is an ORF. (test[1] - test[0][0:len(test[0])])\n",
    "\n",
    "    # get the stop codons minus each start codon, creates a list of arrays, each array corresponds to one start codon subtraction from all stop codons\n",
    "    stop_minus_start = [test[1] - test[0][i] for i in range(len(test[0]))]\n",
    "    print(stop_minus_start)\n",
    "    # if the list has more than one positive value, the index of the lowest + val corresponds to the index of the stop codon at the end of the ORF.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0]\n",
      "[ True  True False]\n"
     ]
    }
   ],
   "source": [
    "# get a list to determine what start codons should be evaluated. (if differences are all negative then there is no possible ORF)\n",
    "\n",
    "diff_lengths = np.array([len(np.zeros(len(stop_minus_start[0]))[stop_minus_start[i] > 0]) for i in range(len(stop_minus_start))])\n",
    "print(diff_lengths)\n",
    "print(diff_lengths > 0) # get logical array of possible start codon position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 10]\n"
     ]
    }
   ],
   "source": [
    "# get the indexes of the start codons to be evalutated.\n",
    "\n",
    "possible_start_inds = start_stop_dict[1][0][diff_lengths > 0]\n",
    "print(possible_start_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# diff_lengths[1] = 0\n",
    "# diff_lengths[2] = 1\n",
    "# find the inds of the \n",
    "# getting the correct indexes for stop_minus_start based on which ones are valid.\n",
    "placeholder_inds = np.arange(len(diff_lengths))\n",
    "print(placeholder_inds)\n",
    "start_codon_inds = placeholder_inds[diff_lengths > 0]\n",
    "print(start_codon_inds)\n",
    "# np.arange(len(diff_lengths))[diff_lengths > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 24]\n",
      "[ True]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45324/3271786097.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_stop_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# gets the list of stop codons for a particular reading frame [1] in this case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_minus_start\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# this is testing the first start codon b/c [0]. gets logical of valid inds for stop codons.append\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_stop_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstop_minus_start\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# gets the first positive difference corresponding the the ORF stop codon for a particular start codon.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpossible_end_inds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstart_stop_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstop_minus_start\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstart_codon_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossible_end_inds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1"
     ]
    }
   ],
   "source": [
    "# get a list of corresponding length, of the stop codons to be evaluating.\n",
    "# for each possible start codon, the stop codon could be different.\n",
    "print(start_stop_dict[1][1]) # gets the list of stop codons for a particular reading frame [1] in this case.\n",
    "print(stop_minus_start[0] > 0) # this is testing the first start codon b/c [0]. gets logical of valid inds for stop codons.append\n",
    "print(start_stop_dict[1][1][stop_minus_start[0] > 0][0]) # gets the first positive difference corresponding the the ORF stop codon for a particular start codon.\n",
    "possible_end_inds = [start_stop_dict[1][1][stop_minus_start[i] > 0][0] for i in start_codon_inds]\n",
    "print(possible_end_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine which stop codon is the end of the ORF\n",
    "# the logical follows that the first non negative difference holds the index of the stop codon\n",
    "test2 = stop_minus_start[0] # [14,16]\n",
    "\n",
    "start_stop_dict[1][1][test2 > 0][0] # np.array([22,24])[True, True][0] = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 22), (10, 22)]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# this gives a list with pairs as ORF's in one reading frame.\n",
    "orfs_1frame = list(zip(possible_start_inds, possible_end_inds))\n",
    "print(orfs_1frame)\n",
    "print(orfs_1frame[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTPRLGLESLLE\n",
      "MLLGSFRLIPKETLIQVAGSSPCNLS\n",
      "MGMTPRLGLESLLE\n",
      "M\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# reading in fasta\n",
    "with open('input.txt', 'r') as raw_fasta:\n",
    "    seq = ''.join(raw_fasta.read().splitlines()[1:])\n",
    "\n",
    "# getting codon dictionary with codons as keys and corresponding amino acids as values\n",
    "with open('dna_codon_table.txt', 'r') as f_codon:\n",
    "    codon_table = f_codon.read().split()\n",
    "    codon_dict = {codon_table[z]: codon_table[z+1] for z in range(0, len(codon_table), 2)}\n",
    "\n",
    "# getting reverse complement\n",
    "complement_dict = {'A':'T', 'T':'A', 'C':'G', 'G':'C'}\n",
    "reverse_complement = ''.join([complement_dict[nuc] for nuc in seq][::-1])\n",
    "\n",
    "# get all 6 reading frames\n",
    "rf_original = [seq[i:] for i in range(3)]\n",
    "rf_reverse_complement = [reverse_complement[i:] for i in range(3)]\n",
    "rf = rf_original + rf_reverse_complement\n",
    "\n",
    "# putting all reading frames into a dict\n",
    "rf_codons = {}\n",
    "for ind, rf_indiv in enumerate(rf):\n",
    "    rf_codons[ind + 1] = [rf_indiv[i:i + 3] for i in range(0,(len(rf_indiv) // 3) * 3, 3)]\n",
    "\n",
    "# getting all start and stop codon positions for each reading frame\n",
    "start_stop_dict = {}\n",
    "for ind, codons in rf_codons.items():\n",
    "    start_stop_dict[ind] = [np.array([index for index, codon in enumerate(codons) if codon == 'ATG']), np.array([index for index, codon in enumerate(codons) if codon in ('TGA', 'TAA', 'TAG')])]\n",
    "\n",
    "\n",
    "# get dictionary with reading frame as key and all ORF's within a frame as values. (orfs_frame_dict)\n",
    "orfs_frame_dict = {}\n",
    "for frame_num, start_stop_dict_frame in start_stop_dict.items(): \n",
    "    # get all ORFs for all 6 reading frames.\n",
    "    if (start_stop_dict_frame[0].size > 0) and (start_stop_dict_frame[1].size > 0): # check there are no empty inds in either start or stop inds.\n",
    "        \n",
    "        # get list of stop codon list minus each start codon \n",
    "        stop_minus_start = [start_stop_dict_frame[1] - start_stop_dict_frame[0][i] for i in range(len(start_stop_dict_frame[0]))]\n",
    "                    \n",
    "        # get lengths of logical arrays that tell how many differences for each start codon are positive(meaning they are possible)\n",
    "        diff_lengths = np.array([len(np.zeros(len(stop_minus_start[0]))[stop_minus_start[i] > 0]) for i in range(len(stop_minus_start))])\n",
    "\n",
    "        # get the inds of the start codons that are in a working ORF. (these inds correspond to the ones in rf_condons[x][:])\n",
    "        possible_start_inds = start_stop_dict_frame[0][diff_lengths > 0]  \n",
    "        if np.any(possible_start_inds): # check that there are possible start inds\n",
    "        # get the inds of the start codons that are in a working ORF (these inds correspond to the ones in stop_minus_start[x])\n",
    "            start_codon_inds = np.arange(len(diff_lengths))[diff_lengths > 0]\n",
    "            possible_end_inds = [start_stop_dict_frame[1][stop_minus_start[i] > 0][0] for i in start_codon_inds]\n",
    "\n",
    "            orfs_frame_dict[frame_num] = list(zip(possible_start_inds, possible_end_inds))\n",
    "\n",
    "# print(start_stop_dict)\n",
    "# print(orfs_frame_dict)\n",
    "\n",
    "# get all codon strings\n",
    "codon_strings = []\n",
    "for k,v in orfs_frame_dict.items():\n",
    "    # print(k,len(v))\n",
    "    for i in range(len(v)):\n",
    "        codon_strings.append(rf_codons[k][v[i][0]: v[i][1]])\n",
    "\n",
    "# translate codon ORFS into amino acids sequences. put them in a set to avoid repeats.\n",
    "proteins = set()\n",
    "for codon_seq in codon_strings:\n",
    "    proteins.add(''.join([codon_dict[codon] for codon in codon_seq]))\n",
    "\n",
    "for protein in proteins:\n",
    "    print(protein) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orfs_frame_dict)\n",
    "orfs_frame_dict[1][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ATG', 'GGG', 'ATG', 'ACC', 'CCG', 'CGA', 'CTT', 'GGA', 'TTA', 'GAG', 'TCT', 'CTT', 'TTG', 'GAA'], ['ATG', 'ACC', 'CCG', 'CGA', 'CTT', 'GGA', 'TTA', 'GAG', 'TCT', 'CTT', 'TTG', 'GAA'], ['ATG'], ['ATG'], ['ATG', 'CTA', 'CTC', 'GGA', 'TCA', 'TTC', 'AGG', 'CTT', 'ATT', 'CCA', 'AAA', 'GAG', 'ACT', 'CTA', 'ATC', 'CAA', 'GTC', 'GCG', 'GGG', 'TCA', 'TCC', 'CCA', 'TGT', 'AAC', 'CTG', 'AGT']]\n"
     ]
    }
   ],
   "source": [
    "# get all codon strings\n",
    "codon_strings = []\n",
    "for k,v in orfs_frame_dict.items():\n",
    "    # print(k,len(v))\n",
    "    for i in range(len(v)):\n",
    "        codon_strings.append(rf_codons[k][v[i][0]: v[i][1]])\n",
    "\n",
    "print(codon_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TTT': 'F', 'CTT': 'L', 'ATT': 'I', 'GTT': 'V', 'TTC': 'F', 'CTC': 'L', 'ATC': 'I', 'GTC': 'V', 'TTA': 'L', 'CTA': 'L', 'ATA': 'I', 'GTA': 'V', 'TTG': 'L', 'CTG': 'L', 'ATG': 'M', 'GTG': 'V', 'TCT': 'S', 'CCT': 'P', 'ACT': 'T', 'GCT': 'A', 'TCC': 'S', 'CCC': 'P', 'ACC': 'T', 'GCC': 'A', 'TCA': 'S', 'CCA': 'P', 'ACA': 'T', 'GCA': 'A', 'TCG': 'S', 'CCG': 'P', 'ACG': 'T', 'GCG': 'A', 'TAT': 'Y', 'CAT': 'H', 'AAT': 'N', 'GAT': 'D', 'TAC': 'Y', 'CAC': 'H', 'AAC': 'N', 'GAC': 'D', 'TAA': 'Stop', 'CAA': 'Q', 'AAA': 'K', 'GAA': 'E', 'TAG': 'Stop', 'CAG': 'Q', 'AAG': 'K', 'GAG': 'E', 'TGT': 'C', 'CGT': 'R', 'AGT': 'S', 'GGT': 'G', 'TGC': 'C', 'CGC': 'R', 'AGC': 'S', 'GGC': 'G', 'TGA': 'Stop', 'CGA': 'R', 'AGA': 'R', 'GGA': 'G', 'TGG': 'W', 'CGG': 'R', 'AGG': 'R', 'GGG': 'G'}\n"
     ]
    }
   ],
   "source": [
    "# translate codon strings into proteins\n",
    "with open('dna_codon_table.txt', 'r') as f_codon:\n",
    "    codon_table = f_codon.read().split()\n",
    "    codon_dict = {codon_table[z]: codon_table[z+1] for z in range(0, len(codon_table), 2)}\n",
    "    \n",
    "print(codon_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTPRLGLESLLE\n",
      "MLLGSFRLIPKETLIQVAGSSPCNLS\n",
      "MGMTPRLGLESLLE\n",
      "M\n"
     ]
    }
   ],
   "source": [
    "# translate codon ORFS into amino acids sequences. put them in a set to avoid repeats.\n",
    "proteins = set()\n",
    "for codon_seq in codon_strings:\n",
    "    proteins.add(''.join([codon_dict[codon] for codon in codon_seq]))\n",
    "\n",
    "for protein in proteins:\n",
    "    print(protein) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\nate\\\\PycharmProjects\\\\rosalind\\\\bioinformatics\\\\Open Reading Frames', 'c:\\\\Users\\\\nate\\\\PycharmProjects\\\\rosalind', 'c:\\\\Users\\\\nate\\\\PycharmProjects\\\\rosalind\\\\bioinformatics', 'c:\\\\Users\\\\nate\\\\PycharmProjects\\\\rosalind\\\\bioinformatics', 'C:\\\\Users\\\\nate\\\\anaconda3\\\\python39.zip', 'C:\\\\Users\\\\nate\\\\anaconda3\\\\DLLs', 'C:\\\\Users\\\\nate\\\\anaconda3\\\\lib', 'C:\\\\Users\\\\nate\\\\anaconda3', '', 'C:\\\\Users\\\\nate\\\\anaconda3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\nate\\\\anaconda3\\\\lib\\\\site-packages\\\\locket-0.2.1-py3.9.egg', 'C:\\\\Users\\\\nate\\\\anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\nate\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\nate\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\nate\\\\anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\nate\\\\.ipython', 'C:\\\\Users\\\\nate\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "# how to import a function from a python file in another directory\n",
    "import sys\n",
    "# print(sys.path)\n",
    "sys.path.insert(1, 'c:\\\\Users\\\\nate\\\\PycharmProjects\\\\rosalind')\n",
    "print(sys.path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosalind import amino_combo_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learn from other solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTPRLGLESLLE\n",
      "M\n",
      "MLLGSFRLIPKETLIQVAGSSPCNLS\n",
      "MGMTPRLGLESLLE\n"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "import re\n",
    "\n",
    "seq = Seq(\"AGCCATGTAGCTAACTCAGGTTACATGGGGATGACCCCGCGACTTGGATTAGAGTCTCTTTTGGAATAAGCCTGAATGATCCGAGTAGCATCTCAG\")\n",
    "\n",
    "orfs = set([])\n",
    "prot = re.compile(\"(?=(M.*?\\*))\")\n",
    "for frame in range(3):\n",
    "    orfs = orfs.union(set(prot.findall(str(seq[frame:(len(seq[frame:]) // 3) * 3].translate()))))\n",
    "    orfs = orfs.union(set(prot.findall(str(seq.reverse_complement()[frame:(len(seq[frame:]) // 3) * 3].translate()))))\n",
    "\n",
    "for i in orfs:\n",
    "    print(i[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHVANSGYMGMTPRLGLESLLE*A*MIRVASQ\n"
     ]
    }
   ],
   "source": [
    "seq = Seq(\"AGCCATGTAGCTAACTCAGGTTACATGGGGATGACCCCGCGACTTGGATTAGAGTCTCTTTTGGAATAAGCCTGAATGATCCGAGTAGCATCTCAG\")\n",
    "print(seq.translate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = set()\n",
    "test.add(1)\n",
    "print(test)\n",
    "test2 = set([1,2])\n",
    "test2.un"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loop based approach instead of reg expression module approach\n",
    "###### side note: shift + l makes the line numberings dissappear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n",
      "MGMTPRLGLESLLE\n",
      "MTPRLGLESLLE\n",
      "MLLGSFRLIPKETLIQVAGSSPCNLS\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def revcomp(s):\n",
    "    r = s.translate(s.maketrans('ACTG','TGAC'))\n",
    "    return r[::-1]\n",
    "\n",
    "dna = \"AGCCATGTAGCTAACTCAGGTTACATGGGGATGACCCCGCGACTTGGATTAGAGTCTCTTTTGGAATAAGCCTGAATGATCCGAGTAGCATCTCAG\"\n",
    "\n",
    "table = \"\"\"TTT F      CTT L      ATT I      GTT V\n",
    "TTC F      CTC L      ATC I      GTC V\n",
    "TTA L      CTA L      ATA I      GTA V\n",
    "TTG L      CTG L      ATG M      GTG V\n",
    "TCT S      CCT P      ACT T      GCT A\n",
    "TCC S      CCC P      ACC T      GCC A\n",
    "TCA S      CCA P      ACA T      GCA A\n",
    "TCG S      CCG P      ACG T      GCG A\n",
    "TAT Y      CAT H      AAT N      GAT D\n",
    "TAC Y      CAC H      AAC N      GAC D\n",
    "TAA Stop   CAA Q      AAA K      GAA E\n",
    "TAG Stop   CAG Q      AAG K      GAG E\n",
    "TGT C      CGT R      AGT S      GGT G\n",
    "TGC C      CGC R      AGC S      GGC G\n",
    "TGA Stop   CGA R      AGA R      GGA G\n",
    "TGG W      CGG R      AGG R      GGG G\"\"\"\n",
    "table = dict(zip(table.split()[::2],table.split()[1::2]))\n",
    "\n",
    "stop = [\"TAA\",\"TAG\",\"TGA\"]\n",
    "proteins = []\n",
    "for s in [dna,revcomp(dna)]:\n",
    "    for i in range(len(s)):\n",
    "        if s[i:i+3] == \"ATG\":\n",
    "            for j in range(i,len(s),3):\n",
    "                if s[j:j+3] in stop:\n",
    "                    c = [s[k:k+3] for k in range(i,j,3)]\n",
    "                    proteins.append( ''.join(map(lambda x:table[x],c)) )\n",
    "                    break\n",
    "for seq in set(proteins):\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TAAGCC'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'ATTCGG'\n",
    "# s.maketrans('ACTG','TGAC')\n",
    "s.translate(s.maketrans('ACTG','TGAC'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d28a1bb2d67e13592803079f57a2d0005ab23fdd1f87a2c5d87e364c23252892"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
